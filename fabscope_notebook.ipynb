{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maskless photolitography with Micro-Manager\n",
    "\n",
    "This workflow is designed for microscopes that can be controlled with uManager drivers (see https://micro-manager.org/Device_Support for a list of all compatible devices).\n",
    "\n",
    "Required hardware device:\n",
    "- Any DMD/SLM capable of projecting images with UV light ([GenericSLM](https://micro-manager.org/GenericSLM))\n",
    "- Light source with UV and another wavelength that does not cure the resin\n",
    "- XY stage to use as stepper (XYStageDevice)\n",
    "- Camera to find focus plane and align layers for 2.5D printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation errors in config file(s).\n",
      "The following fields have been reset to the default value:\n",
      "\n",
      "schema_version\n",
      "  value is not a valid tuple (type=type_error.tuple)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from manager.acquisition import acq, acq_mask\n",
    "from manager.dmd import dmd\n",
    "from manager.fov import FOV\n",
    "from manager.preset import preset\n",
    "from manager.stage import stage_position\n",
    "from utils.fabscope_ui import FabscopeUI\n",
    "    \n",
    "from matplotlib import pyplot as plt \n",
    "from pycromanager import Bridge\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "\n",
    "matplotlib.rcParams[\"image.interpolation\"] = None\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup connection between Pycro-Manager and Micro-Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pycromanager.core.mmcorej_CMMCore object at 0x000001F8467E7400>\n"
     ]
    }
   ],
   "source": [
    "bridge = Bridge() \n",
    "core = bridge.get_core()\n",
    "studio = bridge.get_studio()\n",
    "print(bridge.get_core())\n",
    "dmd = dmd(core) #init dmd device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up basic microscope config (light path, hardware triggering, binning etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andor sCMOS LEFT: Set Binning to 2x2\n",
      "TILightPath: Set State to 2\n",
      "Mosaic3: Set TriggerMode to InternalExpose\n"
     ]
    }
   ],
   "source": [
    "nidaq_setup = preset(core) #focus preset\n",
    "nidaq_setup.settings = [\n",
    "    [\"Spectra RIGHT\",\"Teal_Level\",100],\n",
    "    [\"Spectra RIGHT\",\"Teal_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Cyan_Level\",100],\n",
    "    [\"Spectra RIGHT\",\"Cyan_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Violet_Level\",100],\n",
    "    [\"Spectra RIGHT\",\"Violet_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Green_Level\",100],\n",
    "    [\"Spectra RIGHT\",\"Green_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Blue_Level\",100],\n",
    "    [\"Spectra RIGHT\",\"Blue_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Red_Level\",100],\n",
    "    [\"Spectra RIGHT\",\"Red_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"White_Enable\",0],\n",
    "    ['Andor sCMOS LEFT','AuxiliaryOutSource (TTL I/O)','FireAny']\n",
    "]\n",
    "nidaq_setup.apply_no_retry()\n",
    "\n",
    "camera_setup = preset(core) #focus preset\n",
    "camera_setup.settings = [\n",
    "    [\"Andor sCMOS LEFT\",\"Binning\",'2x2'],\n",
    "    [\"TILightPath\",\"State\",'2'],\n",
    "    [\"Mosaic3\",\"TriggerMode\",'InternalExpose'],\n",
    "]\n",
    "camera_setup.apply(core)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardware setup for UV exposure\n",
    "The channel/light source you want to activate when doing a UV exposure of the resin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectra RIGHT: Set Teal_Enable to 0\n",
      "Spectra RIGHT: Set Cyan_Enable to 0\n",
      "Spectra RIGHT: Set Violet_Enable to 1\n",
      "Spectra RIGHT: Set Blue_Enable to 0\n",
      "Spectra RIGHT: Set Red_Enable to 0\n",
      "TIFilterBlock1: Set State to 1\n",
      "Wheel-C: Set State to 1\n",
      "Spectra RIGHT: Set Green_Enable to 0\n",
      "Spectra RIGHT: Set Violet_Level to 100\n"
     ]
    }
   ],
   "source": [
    "expose_UV = preset(core)\n",
    "expose_UV.settings = [\n",
    "    [\"Spectra RIGHT\",\"Teal_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Cyan_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Violet_Enable\",1],\n",
    "    [\"Spectra RIGHT\",\"Blue_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Red_Enable\",0],\n",
    "    [\"TIFilterBlock1\", \"State\", \"1\"],#2 \n",
    "    [\"Wheel-C\", \"State\", 1],\n",
    "    [\"Spectra RIGHT\",\"Green_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Violet_Level\",100]\n",
    "]\n",
    "expose_UV.camera_exposure_time = 250 \n",
    "expose_UV.name = 'expose_UV'\n",
    "expose_UV.apply(core)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardware setup for focus checking\n",
    "A light source that does not cure the resin, in our case a red LED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_RED = preset(core)\n",
    "check_RED.settings = [ \n",
    "    [\"TIFilterBlock1\", \"State\", \"1\"],\n",
    "    [\"Wheel-C\", \"State\", 2], \n",
    "    [\"Spectra RIGHT\",\"Teal_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Cyan_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Violet_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Green_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Blue_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Red_Enable\",1],\n",
    "    [\"Spectra RIGHT\",\"Red_Level\",50] \n",
    "]\n",
    "check_RED.camera_exposure_time = 5 \n",
    "check_RED.dmd_exposure_time = 250\n",
    "check_RED.name = \"check_RED\"\n",
    "check_RED.apply()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardware settings to turn off all lights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark = preset(core)\n",
    "dark.settings = [\n",
    "    [\"Spectra RIGHT\",\"Teal_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Cyan_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Violet_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Green_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Blue_Enable\",0],\n",
    "    [\"Spectra RIGHT\",\"Red_Enable\",0],\n",
    "    [\"Wheel-C\", \"State\", 0],\n",
    "]\n",
    "dark.name = 'BLACK'\n",
    "dark.apply()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add all channels to the list that should show up in the user interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [expose_UV,check_RED,dark]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the napari GUI for liveview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viewer already closed or never opened\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_RED\n",
      "stopping threads\n",
      "starting threads...\n",
      "Worker started: yield_img\n",
      "Worker started: append_img\n",
      "Warning: No image in uManager queue.\n",
      "stopping threads\n",
      "acquisition done\n",
      "starting threads...\n",
      "Worker started: yield_img\n",
      "Worker started: append_img\n",
      "stopping threads\n",
      "acquisition done\n"
     ]
    }
   ],
   "source": [
    "viewer = FabscopeUI(\n",
    "    core=core,\n",
    "    dmd=dmd,\n",
    "    channels=channels,\n",
    "    simulate=False,\n",
    "    sleep_time=0.1,\n",
    "    clim=(0, 255)\n",
    ")\n",
    "\n",
    "# Initialize and show the viewer\n",
    "viewer.initialize_viewer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New calibration of the X/Y step size\n",
    "How much should the stage move between FOVs?\n",
    "To calibrate, first \n",
    "1. Make a full FOV exposure with UV to cure the resin (`position_1`)\n",
    "2. Turn on the other light source that does note cure the resin\n",
    "3. Move the stage to align the so that the current top left corner precisely touches the bottom right corner of the printed structure (`position_2`)\n",
    "\n",
    "By calculating the vector between the two positions, we get the x/y translation needed.\n",
    "\n",
    "For our 20x objective, the values are:\n",
    "`x_offset = 660.7`\n",
    "`y_offset = 482.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epose the whole FOV and store the first position\n",
    "mask = np.ones((600,800)).astype('uint8')\n",
    "stim_img = acq_mask(mask, expose_UV, dmd)\n",
    "position_1 = core.get_xy_stage_position()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now move to position 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6114.20009110868\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# store the second position\n",
    "position_2 = core.get_xy_stage_position()\n",
    "\n",
    "x_offset = position_1.get_x()-position_2.get_x()\n",
    "y_offset = position_1.get_y()-position_2.get_y()\n",
    "\n",
    "print(x_offset)\n",
    "print(y_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a previously measured X/Y step size (or adapt it to a different objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_objective = 20 #objective that was used for calibration\n",
    "current_objective = 20 #objective that is currently used\n",
    "\n",
    "#measured offset\n",
    "y_offset = 482.5 \n",
    "x_offset = 660.7\n",
    "\n",
    "y_offset = calibration_objective/current_objective*485\n",
    "x_offset = calibration_objective/current_objective*655"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a large image mask and tile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mask_handler import load_mask, tile_array, visualize_tiles\n",
    "\n",
    "# Define the base path\n",
    "base_path = 'Z:\\\\PertzLab\\\\lhinder\\\\micropatterning'\n",
    "\n",
    "# Load a mask\n",
    "mask = load_mask(base_path, 'your_mask_file.tif', invert=False)\n",
    "\n",
    "# Split into tiles with custom dimensions if needed\n",
    "tiles, grid_width, grid_height = tile_array(mask, tile_width=800, tile_height=600)\n",
    "\n",
    "# Optionally visualize the tiles\n",
    "visualize_tiles(tiles, grid_width, grid_height)\n",
    "print(f'Number of tiles: {len(tiles)}, {grid_width}x{grid_height} (rows x cols)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expose the mask, stepping through all tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_calibration = False #produce a exposure calibration grid\n",
    "test_mode = False #use red LED instead of UV, to check if the stage is moving as expected\n",
    "\n",
    "#store the led power setting and exposure time for the UV LED you want to test in an array\n",
    "led_powers = np.linspace(10,100,grid_width).astype(int)\n",
    "exposure_times = np.linspace(10,1,grid_height).astype(int)\n",
    "\n",
    "#check if led_powers and exposure_times are same lenght as grid_width and grid_height\n",
    "if len(led_powers) != grid_width:\n",
    "    print('led_powers and grid_width are not the same length')\n",
    "if len(exposure_times) != grid_height:\n",
    "    print('exposure_times and grid_height are not the same length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:47<00:00,  1.08s/it]\n",
      "100%|██████████| 100/100 [01:45<00:00,  1.06s/it]\n",
      "100%|██████████| 100/100 [01:49<00:00,  1.09s/it]\n",
      "100%|██████████| 100/100 [01:51<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "point = core.get_xy_stage_position()\n",
    "x_pos = point.get_x()\n",
    "y_pos = point.get_y()\n",
    "\n",
    "pos = stage_position(x_pos,y_pos,None)\n",
    "fov_start = FOV(core, pos, 'treatment', 2,  10, 10,10)\n",
    "fov = fov_start\n",
    "\n",
    "exposure_preset = expose_UV if not test_mode else check_RED\n",
    "\n",
    "stim_imgs = []\n",
    "with tqdm(total=grid_width*grid_height) as pbar:\n",
    "    for col in range(grid_width):\n",
    "        for row in range(grid_height):\n",
    "            y_pos_new = y_pos+(row*y_offset)\n",
    "            x_pos_new = x_pos+(col*x_offset)\n",
    "            pos = stage_position(x_pos_new,y_pos_new,None)\n",
    "            fov = FOV(core, pos, 'treatment', 2, 10, 10, 10)\n",
    "            fov.move_stage_to_fov()\n",
    "\n",
    "            if exposure_calibration:\n",
    "                exposure_preset.camera_exposure_time = exposure_times[row]\n",
    "                exposure_preset.set_power(led_powers[col])\n",
    "                exposure_preset.apply()\n",
    "\n",
    "            stim_img = acq_mask(tiles[row][col], exposure_preset, dmd)\n",
    "            stim_imgs.append(stim_img)\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "fov_start.move_stage_to_fov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QC of the stimulation images\n",
    "When exposing the layer with UV light, we also acquire the image. This can be useful for trouble shooting, e.g. detecting impurities or focus drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(stim_imgs[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
